# backend/api_handler.py
import os
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import logging
import shutil
import xml.etree.ElementTree as ET
import subprocess
import signal
from flask import Blueprint, request, jsonify, current_app, send_from_directory
from db_manager import get_db_connection
import image_processor
from config_utils import get_settings, save_settings, get_restart_required_settings
from nfo_parser import parse_nfo_file
from notification_sender import send_test_notification
import uuid
import tempfile
from werkzeug.utils import secure_filename
import urllib.parse
import re
from bs4 import BeautifulSoup
import time
import threading

# å¯¼å…¥å·¥å…·ç±»
from utils import (is_safe_path as utils_is_safe_path, get_safe_filename,
                  ensure_dir_exists, HTTP_HEADERS, safe_rename, safe_copy, safe_delete)

# å¯¼å…¥æ€§èƒ½ä¼˜åŒ–æ¨¡å—
from db_performance import db_performance_optimizer
from cache_manager import cache_manager
from monitoring import monitoring_system
from performance_test import performance_tester

# åˆ›å»ºä¼˜åŒ–çš„HTTP Sessionï¼Œæ”¯æŒè¿æ¥å¤ç”¨å’ŒKeep-Alive
def create_optimized_session():
    """åˆ›å»ºä¼˜åŒ–çš„requests Sessionï¼Œæ”¯æŒè¿æ¥æ± å’Œé‡è¯•"""
    session = requests.Session()

    # é…ç½®é‡è¯•ç­–ç•¥
    retry_strategy = Retry(
        total=2,  # æ€»é‡è¯•æ¬¡æ•°
        backoff_factor=0.5,  # é‡è¯•é—´éš”
        status_forcelist=[429, 500, 502, 503, 504],  # éœ€è¦é‡è¯•çš„çŠ¶æ€ç 
    )

    # é…ç½®HTTPé€‚é…å™¨ï¼Œæ”¯æŒè¿æ¥æ± 
    adapter = HTTPAdapter(
        pool_connections=10,  # è¿æ¥æ± å¤§å°
        pool_maxsize=20,      # æ¯ä¸ªè¿æ¥æ± çš„æœ€å¤§è¿æ¥æ•°
        max_retries=retry_strategy,
        pool_block=False      # éé˜»å¡æ¨¡å¼
    )

    # ä¸ºHTTPå’ŒHTTPSé…ç½®é€‚é…å™¨
    session.mount("http://", adapter)
    session.mount("https://", adapter)

    # å¯ç”¨Keep-Aliveï¼ˆé»˜è®¤å·²å¯ç”¨ï¼Œä½†æ˜ç¡®è®¾ç½®ï¼‰
    session.headers.update({
        'Connection': 'keep-alive',
        'Keep-Alive': 'timeout=30, max=100'
    })

    return session

# åˆ›å»ºå…¨å±€Sessionå®ä¾‹ï¼Œç”¨äºé“¾æ¥éªŒè¯
_http_session = create_optimized_session()

# DMMåŸŸåç¼“å­˜
_dmm_domain_cache = {
    'status': None,  # 'available', 'unavailable', None
    'last_check': None,
    'cache_duration': 300  # 5åˆ†é’Ÿç¼“å­˜
}

def check_dmm_domain_availability():
    """æ£€æŸ¥DMMåŸŸåå¯ç”¨æ€§ - è·³è¿‡æ£€æµ‹ï¼Œç›´æ¥è¿”å›å¯ç”¨"""
    # ç”¨æˆ·ç¡®è®¤ç½‘ç«™å¯ä»¥è®¿é—®ï¼Œè·³è¿‡åŸŸåæ£€æµ‹ä»¥é¿å…ä¸å¿…è¦çš„å»¶è¿Ÿ
    return True

def is_dmm_url(url):
    """åˆ¤æ–­æ˜¯å¦ä¸ºDMMé“¾æ¥"""
    return url and 'awsimgsrc.dmm.co.jp' in url

api = Blueprint('api', __name__)
# æ”¹ä¸ºä»é…ç½®ä¸­è·å–åª’ä½“æ ¹è·¯å¾„
def get_media_root():
    return get_settings().get('media_root', '/weiam')

# å°é¢ç¼“å­˜ç›¸å…³å‡½æ•°
def get_cover_cache_dir():
    """è·å–å°é¢ç¼“å­˜ç›®å½•è·¯å¾„"""
    settings = get_settings()
    # é»˜è®¤åœ¨cover_cacheç›®å½•ä¸‹ï¼ˆä¸logsã€dbç­‰ç›®å½•åŒçº§ï¼‰
    cache_dir = settings.get('cover_cache_dir', 'cover_cache')
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    ensure_dir_exists(cache_dir)
    return cache_dir

def copy_to_cover_cache(poster_path, strm_name):
    """å°†å°é¢å›¾ç‰‡å¤åˆ¶åˆ°ç¼“å­˜ç›®å½•"""
    if not poster_path or not strm_name:
        current_app.logger.warning(f"ç¼“å­˜å°é¢å¤±è´¥: æ— æ•ˆçš„å‚æ•°ï¼Œposter_path={poster_path}, strm_name={strm_name}")
        return None
        
    # æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(poster_path):
        current_app.logger.warning(f"ç¼“å­˜å°é¢å¤±è´¥: æºæ–‡ä»¶ä¸å­˜åœ¨ - {poster_path}")
        return None
        
    if not os.path.isfile(poster_path):
        current_app.logger.warning(f"ç¼“å­˜å°é¢å¤±è´¥: æºè·¯å¾„ä¸æ˜¯æ–‡ä»¶ - {poster_path}")
        return None
    
    try:
        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        cache_dir = get_cover_cache_dir()
        
        # ä½¿ç”¨strm_nameçš„å®Œæ•´è·¯å¾„ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„æ–‡ä»¶åï¼Œç¡®ä¿ä¸åŒè·¯å¾„çš„åŒåå½±ç‰‡ä¸ä¼šå†²çª
        # ä½¿ç”¨è·¯å¾„ä¿¡æ¯è®¡ç®—å“ˆå¸Œï¼Œä½œä¸ºæ–‡ä»¶åå‰ç¼€ï¼Œä¿ç•™åŸå§‹ç•ªå·ä½œä¸ºæ–‡ä»¶åä¸»ä½“éƒ¨åˆ†
        import hashlib
        # è®¡ç®—strm_name (é€šå¸¸æ˜¯è·¯å¾„) çš„å“ˆå¸Œå€¼çš„å‰8ä½ä½œä¸ºå‰ç¼€
        name_hash = hashlib.md5(strm_name.encode('utf-8')).hexdigest()[:8]
        # ä»strm_nameä¸­æå–ç•ªå·éƒ¨åˆ†ä½œä¸ºæ–‡ä»¶åä¸»ä½“
        base_name = os.path.basename(strm_name)
        if '.' in base_name:
            base_name = base_name.split('.')[0]  # ç§»é™¤æ–‡ä»¶æ‰©å±•å
            
        # ç»“åˆå“ˆå¸Œå’Œç•ªå·åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å
        safe_name = f"{name_hash}_{get_safe_filename(base_name)}"
        current_app.logger.debug(f"ç”Ÿæˆç¼“å­˜æ–‡ä»¶å: {safe_name} (æ¥æº: {strm_name})")
            
        dest_path = os.path.join(cache_dir, f"{safe_name}.jpg")
        
        # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ä¸”æœ€è¿‘æ›´æ–°è¿‡ï¼ˆ1å°æ—¶å†…ï¼‰ï¼Œè·³è¿‡å¤åˆ¶
        if os.path.exists(dest_path):
            source_mtime = os.path.getmtime(poster_path)
            dest_mtime = os.path.getmtime(dest_path)
            
            # å¦‚æœç›®æ ‡æ–‡ä»¶æ¯”æºæ–‡ä»¶æ–°ï¼Œæˆ–è€…ä¸è¶…è¿‡1å°æ—¶ï¼Œåˆ™ä¸æ›´æ–°
            one_hour = 60 * 60  # ç§’æ•°
            if dest_mtime >= source_mtime or (time.time() - dest_mtime) < one_hour:
                current_app.logger.debug(f"ç¼“å­˜å°é¢å·²å­˜åœ¨ä¸”è¾ƒæ–°: {safe_name}")
                return dest_path
        
        # ä½¿ç”¨å®‰å…¨å¤åˆ¶å‡½æ•°        
        success, error = safe_copy(poster_path, dest_path)
        if success:
            current_app.logger.info(f"å·²ç¼“å­˜å°é¢: {safe_name}")
            return dest_path
        else:
            current_app.logger.error(f"ç¼“å­˜å°é¢å¤±è´¥: {error}")
            return None
    except Exception as e:
        current_app.logger.error(f"ç¼“å­˜å°é¢å¤±è´¥: {str(e)}")
        return None

def clean_cover_cache(max_covers=100):
    """æ¸…ç†å¤šä½™çš„å°é¢ç¼“å­˜ï¼Œä¿ç•™ä¸æ•°æ®åº“ä¸­æœ€æ–°é¡¹ç›®åŒ¹é…çš„ç¼“å­˜"""
    try:
        # ç¡®ä¿max_coversæ˜¯æ•´æ•°
        if isinstance(max_covers, str):
            try:
                max_covers = int(max_covers)
            except ValueError:
                current_app.logger.error(f"max_coverså‚æ•°æ ¼å¼é”™è¯¯: '{max_covers}'ï¼Œåº”ä¸ºæ•´æ•°")
                max_covers = 24  # ä½¿ç”¨é»˜è®¤å€¼
        
        cache_dir = get_cover_cache_dir()
        # å•æ¬¡æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”æ˜¯ç›®å½•
        if not os.path.isdir(cache_dir):
            return
        
        # å…ˆè·å–æ‰€æœ‰ç¼“å­˜çš„å°é¢æ–‡ä»¶
        cache_files = {}
        for filename in os.listdir(cache_dir):
            if filename.endswith('.jpg'):
                file_path = os.path.join(cache_dir, filename)
                # ç¡®ä¿æ˜¯æ–‡ä»¶è€Œéç›®å½•
                if os.path.isfile(file_path):
                    cache_files[filename] = file_path
        
        # å¦‚æœæ²¡æœ‰ç¼“å­˜æ–‡ä»¶ï¼Œç›´æ¥è¿”å›
        if not cache_files:
            current_app.logger.debug("æ²¡æœ‰å°é¢ç¼“å­˜æ–‡ä»¶ï¼Œæ— éœ€æ¸…ç†")
            return
        
        # è·å–æœ€æ–°çš„é¡¹ç›®åˆ—è¡¨
        latest_items = _get_latest_high_quality_items(max_covers)
        
        # ä¸ºæ¯ä¸ªé¡¹ç›®ç”Ÿæˆå¯èƒ½çš„ç¼“å­˜æ–‡ä»¶ååˆ—è¡¨ï¼ˆåŒ…æ‹¬æ–°æ—§å‘½åæ–¹å¼ï¼‰
        to_keep_filenames = set()
        
        for item in latest_items:
            strm_name = item.get('strm_name')
            if not strm_name:
                continue
            
            # æ–°å‘½åæ–¹å¼
            import hashlib
            name_hash = hashlib.md5(strm_name.encode('utf-8')).hexdigest()[:8]
            base_name = os.path.basename(strm_name)
            if '.' in base_name:
                base_name = base_name.split('.')[0]
                
            safe_name = f"{name_hash}_{get_safe_filename(base_name)}"
            new_filename = f"{safe_name}.jpg"
            to_keep_filenames.add(new_filename)
            
            # æ—§å‘½åæ–¹å¼
            old_safe_name = get_safe_filename(strm_name)
            old_filename = f"{old_safe_name}.jpg"
            to_keep_filenames.add(old_filename)
        
        # æ‰¾å‡ºéœ€è¦åˆ é™¤çš„æ–‡ä»¶
        to_delete = []
        for filename, filepath in cache_files.items():
            if filename not in to_keep_filenames:
                to_delete.append(filepath)
        
        # å¦‚æœæ²¡æœ‰éœ€è¦åˆ é™¤çš„æ–‡ä»¶ï¼Œè¿”å›
        if not to_delete:
            current_app.logger.debug(f"æ‰€æœ‰ç¼“å­˜æ–‡ä»¶({len(cache_files)})ä¸æœ€æ–°é¡¹ç›®åŒ¹é…ï¼Œæ— éœ€æ¸…ç†")
            return
        
        # åˆ é™¤ä¸åœ¨ä¿ç•™åˆ—è¡¨ä¸­çš„ç¼“å­˜æ–‡ä»¶
        deleted_count = 0
        for path in to_delete:
            success, _ = safe_delete(path)
            if success:
                deleted_count += 1
                current_app.logger.debug(f"å·²åˆ é™¤ä¸åŒ¹é…çš„å°é¢ç¼“å­˜: {os.path.basename(path)}")
        
        if deleted_count > 0:
            current_app.logger.info(f"å·²æ¸…ç†å°é¢ç¼“å­˜: åˆ é™¤äº†{deleted_count}ä¸ªä¸åŒ¹é…å½“å‰é¡¹ç›®çš„æ–‡ä»¶")
            
    except Exception as e:
        current_app.logger.error(f"å°é¢ç¼“å­˜æ¸…ç†è¿‡ç¨‹å‡ºé”™: {str(e)}", exc_info=True)
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“ä¸»è¦åŠŸèƒ½

def manage_cover_cache():
    """ç®¡ç†å°é¢ç¼“å­˜ï¼Œç¡®ä¿ç¼“å­˜ä¸è¶…è¿‡è®¾ç½®çš„æ•°é‡"""
    settings = get_settings()
    # ç¡®ä¿latest_movies_countæ˜¯æ•´æ•°
    try:
        max_covers = int(settings.get('latest_movies_count', 24))
    except (TypeError, ValueError):
        max_covers = 24  # ä½¿ç”¨é»˜è®¤å€¼
        
    current_app.logger.debug(f"å‡†å¤‡æ¸…ç†å°é¢ç¼“å­˜ï¼Œä¿ç•™æœ€æ–°{max_covers}ä¸ª")
    clean_cover_cache(max_covers)

def get_cached_cover_path(strm_name):
    """è·å–ç¼“å­˜çš„å°é¢è·¯å¾„ï¼Œå¦‚æœå­˜åœ¨"""
    if not strm_name:
        return None
    
    try:
        cache_dir = get_cover_cache_dir()
        
        # ä½¿ç”¨ä¸copy_to_cover_cacheç›¸åŒçš„é€»è¾‘ç”Ÿæˆæ–‡ä»¶å
        import hashlib
        name_hash = hashlib.md5(strm_name.encode('utf-8')).hexdigest()[:8]
        base_name = os.path.basename(strm_name)
        if '.' in base_name:
            base_name = base_name.split('.')[0]
            
        safe_name = f"{name_hash}_{get_safe_filename(base_name)}"
        cached_path = os.path.join(cache_dir, f"{safe_name}.jpg")
        
        if os.path.exists(cached_path):
            return cached_path
            
        # å‘åå…¼å®¹ï¼šå°è¯•æ—§çš„å‘½åæ–¹å¼
        old_safe_name = get_safe_filename(strm_name)
        old_cached_path = os.path.join(cache_dir, f"{old_safe_name}.jpg")
        if os.path.exists(old_cached_path):
            current_app.logger.debug(f"æ‰¾åˆ°æ—§æ ¼å¼çš„ç¼“å­˜æ–‡ä»¶: {old_safe_name}")
            return old_cached_path
            
    except Exception as e:
        current_app.logger.error(f"æŸ¥æ‰¾ç¼“å­˜å°é¢å¤±è´¥: {str(e)}")
    
    return None

class ScrapeError(Exception):
    """ç”¨äºæŠ“å–è¿‡ç¨‹ä¸­çš„é”™è¯¯å¤„ç†"""
    pass

def scrape_cid(bangou: str) -> str:
    """
    ä» avbase.net æœç´¢å¹¶è§£æå‡º CID
    """
    search_url = f"https://www.avbase.net/works?q={urllib.parse.quote(bangou)}"
    current_app.logger.info(f"æ­£åœ¨è®¿é—®: {search_url}")
    try:
        response = requests.get(search_url, headers=HTTP_HEADERS, timeout=20)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'lxml')
        
        fanza_img = soup.find('img', alt='fanza')
        
        if not fanza_img:
            raise ScrapeError(f"åœ¨AVBaseé¡µé¢ä¸­æœªæ‰¾åˆ° 'fanza' å›¾æ ‡ (å¯èƒ½æ— æ­¤ç•ªå·è®°å½•æˆ–é¡µé¢ç»“æ„å·²æ›´æ”¹)")
            
        fanza_anchor = fanza_img.find_parent('a')
        if not fanza_anchor or not fanza_anchor.has_attr('href'):
            raise ScrapeError("æ‰¾åˆ°äº†'fanza'å›¾æ ‡ï¼Œä½†æœªèƒ½æ‰¾åˆ°å…¶åŒ…å«é“¾æ¥çš„çˆ¶æ ‡ç­¾")
            
        dmm_url_encoded = fanza_anchor['href']
        dmm_url_decoded = urllib.parse.unquote(dmm_url_encoded)
        
        match = re.search(r'cid=([a-zA-Z0-9_]+)', dmm_url_decoded)
        if not match:
            raise ScrapeError(f"åœ¨è§£ç åçš„é“¾æ¥ä¸­æœªèƒ½è§£æå‡ºCID: {dmm_url_decoded}")
            
        found_cid = match.group(1)
        current_app.logger.info(f"æˆåŠŸæ‰¾åˆ°CID: {found_cid}")
        return found_cid
        
    except requests.exceptions.RequestException as e:
        raise ScrapeError(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}")

# æ·»åŠ æ–°çš„APIç«¯ç‚¹ç”¨äºæ‰‹åŠ¨è·å–CIDä¿¡æ¯
@api.route('/get-manual-cid-info', methods=['GET'])
def get_manual_cid_info():
    bangou = request.args.get('bangou')
    if not bangou: return jsonify({"success": False, "message": "éœ€è¦æä¾›ç•ªå·"}), 400
    
    try:
        # ä½¿ç”¨scrape_cidè·å–CID
        cid = scrape_cid(bangou)
        
        if not cid:
            return jsonify({"success": False, "message": "æœªæ‰¾åˆ°CID"}), 404
        
        # ä¸ get_dmm_info ä¸€æ ·æ„é€ ç»“æœ
        parts = cid.split('00')
        code = parts[0] + parts[-1].zfill(5) if len(parts) > 1 else cid
        

        
        result = {
            "cid": cid,
            "rule_info": {"manual": True},
            "wallpaper_url": {"url": f"https://awsimgsrc.dmm.co.jp/pics_dig/digital/video/{code}/{code}pl.jpg"},
            "cover_url": {"url": f"https://awsimgsrc.dmm.co.jp/pics_dig/digital/video/{code}/{code}ps.jpg"}
        }
        
        return jsonify({"success": True, "results": [result]})
        
    except ScrapeError as e:
        current_app.logger.error(f"æ‰‹åŠ¨è·å–CIDå¤±è´¥: {e}")
        return jsonify({"success": False, "message": f"è·å–CIDå¤±è´¥: {e}"}), 404
    except Exception as e:
        current_app.logger.error(f"æ‰‹åŠ¨è·å–CIDæ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        return jsonify({"success": False, "message": f"å¤„ç†è¯·æ±‚å¤±è´¥: {e}"}), 500

def is_safe_path(path):
    """
    æ£€æŸ¥è¯·æ±‚è·¯å¾„æ˜¯å¦åœ¨å…è®¸çš„åª’ä½“æ ¹ç›®å½•å†…çš„åŒ…è£…å‡½æ•°
    
    Args:
        path: è¦æ£€æŸ¥çš„è·¯å¾„
        
    Returns:
        bool: å¦‚æœè·¯å¾„å®‰å…¨åˆ™è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    return utils_is_safe_path(path, get_media_root())

@api.route('/settings', methods=['GET'])
def get_settings_route(): 
    """è·å–è®¾ç½®ï¼Œå¹¶æ ‡è®°å“ªäº›è®¾ç½®éœ€è¦é‡å¯"""
    settings = get_settings()
    restart_required = get_restart_required_settings()
    
    # æ·»åŠ éœ€è¦é‡å¯çš„è®¾ç½®æ ‡è®°
    return jsonify({
        "settings": settings,
        "restart_required_settings": restart_required
    })

@api.route('/settings', methods=['POST'])
def save_settings_route():
    """ä¿å­˜è®¾ç½®ï¼Œå¹¶è¿”å›æ˜¯å¦éœ€è¦é‡å¯çš„ä¿¡æ¯"""
    new_settings = request.json
    
    # è·å–å½“å‰è®¾ç½®ï¼Œç”¨äºæ¯”è¾ƒå˜åŒ–
    current_settings = get_settings()
    
    # ä¿å­˜è®¾ç½®
    success, message, restart_needed = save_settings(new_settings, current_settings)
    
    if success:
        # æ›´æ–°æ—¥å¿—çº§åˆ«ï¼Œè¿™æ˜¯å”¯ä¸€ä¸€ä¸ªå¯ä»¥ä¸é‡å¯å°±ç”Ÿæ•ˆçš„"éœ€è¦é‡å¯"çš„è®¾ç½®
        if 'log_level' in new_settings:
            log_level_str = new_settings.get('log_level', 'INFO').upper()
            new_level = getattr(logging, log_level_str, logging.INFO)
            current_app.logger.setLevel(new_level)
            for handler in current_app.logger.handlers: 
                handler.setLevel(new_level)
            current_app.logger.info(f"æ—¥å¿—çº§åˆ«å·²æ›´æ–°ä¸º: {log_level_str}")
        
        return jsonify({
            "success": True, 
            "message": message,
            "restart_needed": restart_needed
        })
    
    return jsonify({"success": False, "message": message}), 500

@api.route('/test-notification', methods=['POST'])
def test_notification_route():
    """æµ‹è¯•é€šçŸ¥å‘é€åŠŸèƒ½å¹¶è¿”å›è¯¦ç»†ç»“æœ"""
    try:
        with current_app.app_context():
            # è·å–å½“å‰è®¾ç½®ä»¥è®°å½•æ—¥å¿—
            settings = get_settings()
            notification_api_url = settings.get('notification_api_url', '')
            notification_type = settings.get('notification_type', 'custom')

            # è®°å½•æµ‹è¯•å¼€å§‹æ—¥å¿—
            current_app.logger.info(f"å¼€å§‹æµ‹è¯•{notification_type}ç±»å‹é€šçŸ¥å‘é€ï¼Œ"
                               f"APIåœ°å€: {notification_api_url if notification_type == 'custom' else 'telegram'}")
            
            # è¿›è¡Œç½‘ç»œè¿æ¥æµ‹è¯•
            if notification_type == 'custom':
                host = notification_api_url.split('://')[1].split(':')[0].split('/')[0] if '://' in notification_api_url else notification_api_url
                port = 5400  # é»˜è®¤ç«¯å£ï¼Œå¯èƒ½éœ€è¦ä»URLä¸­è§£æ
                try:
                    parts = notification_api_url.split('://')[1].split(':', 1)
                    if len(parts) > 1:
                        port_str = parts[1].split('/', 1)[0]
                        if port_str.isdigit():
                            port = int(port_str)
                except Exception as e:
                    current_app.logger.warning(f"ä»URLè§£æç«¯å£å¤±è´¥: {e}, ä½¿ç”¨é»˜è®¤ç«¯å£5400")
                
                # è¿›è¡Œè¿æ¥æµ‹è¯•
                current_app.logger.info(f"æµ‹è¯•è¿æ¥åˆ°ä¸»æœº: {host}:{port}")
                import socket
                try:
                    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                    s.settimeout(5)
                    result = s.connect_ex((host, port))
                    if result == 0:
                        current_app.logger.info(f"è¿æ¥æµ‹è¯•æˆåŠŸ: {host}:{port} å¯è®¿é—®")
                    else:
                        current_app.logger.warning(f"è¿æ¥æµ‹è¯•å¤±è´¥: {host}:{port} ä¸å¯è®¿é—®ï¼Œé”™è¯¯ç : {result}")
                except Exception as e:
                    current_app.logger.warning(f"è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
                finally:
                    s.close()
            
            # --- è°ƒç”¨ä¸“ç”¨çš„æµ‹è¯•å‡½æ•° ---
            send_test_notification()
            return jsonify({"success": True, "message": "æµ‹è¯•é€šçŸ¥å·²å‘é€ï¼Œè¯·æ£€æŸ¥æ‚¨çš„é€šçŸ¥æœåŠ¡ã€‚"})
    except requests.exceptions.Timeout as e:
        error_msg = f"å‘é€æµ‹è¯•é€šçŸ¥è¶…æ—¶: {e}"
        current_app.logger.error(error_msg, exc_info=True)
        return jsonify({"success": False, "message": error_msg}), 500
    except requests.exceptions.ConnectionError as e:
        error_msg = f"å‘é€æµ‹è¯•é€šçŸ¥è¿æ¥å¤±è´¥: {e}"
        current_app.logger.error(error_msg, exc_info=True)
        return jsonify({"success": False, "message": error_msg}), 500
    except ValueError as e:
        error_msg = f"é€šçŸ¥é…ç½®é”™è¯¯: {e}"
        current_app.logger.error(error_msg, exc_info=True)
        return jsonify({"success": False, "message": error_msg}), 400
    except Exception as e:
        error_msg = f"å‘é€æµ‹è¯•é€šçŸ¥å¤±è´¥: {e}"
        current_app.logger.error(error_msg, exc_info=True)
        return jsonify({"success": False, "message": error_msg}), 500

@api.route('/latest-items')
def get_latest_items():
    settings = get_settings()
    count = settings.get('latest_movies_count', 24)
    
    # è·å–æœ€æ–°çš„é«˜ç”»è´¨é¡¹ç›®
    items_list = _get_latest_high_quality_items(count)
    
    # å¤„ç†å°é¢ç¼“å­˜
    use_cache = settings.get('use_cover_cache', True)  # é»˜è®¤å¯ç”¨ç¼“å­˜
    
    if use_cache:
        for item in items_list:
            strm_name = item.get('strm_name')
            poster_path = item.get('poster_path')
            
            if strm_name and poster_path:
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰ç¼“å­˜
                cached_path = get_cached_cover_path(strm_name)
                
                if not cached_path:
                    # ç¼“å­˜ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º
                    cached_path = copy_to_cover_cache(poster_path, strm_name)
                
                if cached_path:
                    # ä½¿ç”¨ç¼“å­˜è·¯å¾„æ›¿æ¢åŸå§‹è·¯å¾„
                    item['original_poster_path'] = poster_path  # ä¿ç•™åŸå§‹è·¯å¾„
                    
                    # ç¡®ä¿è·¯å¾„æ ¼å¼ä¸º 'cover_cache/æ–‡ä»¶å.jpg'
                    # æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦å†æ¬¡è°ƒç”¨secure_filenameï¼Œå› ä¸ºcopy_to_cover_cacheå’Œget_cached_cover_pathå·²ç»å¤„ç†è¿‡äº†
                    item['poster_path'] = os.path.join('cover_cache', os.path.basename(cached_path))
                    
                    # è®°å½•è°ƒè¯•ä¿¡æ¯
                    current_app.logger.debug(f"ä½¿ç”¨ç¼“å­˜å°é¢: {item['poster_path']} (åŸè·¯å¾„: {poster_path})")
        
        # ç®¡ç†ç¼“å­˜ï¼Œåˆ é™¤å¤šä½™çš„
        manage_cover_cache()
    
    return jsonify(items_list)

@api.route('/low-quality-items', methods=['GET'])
def get_low_quality_items():
    try:
        page = request.args.get('page', 1, type=int)
        per_page = 10
        offset = (page - 1) * per_page
        conn = get_db_connection()
        query = "SELECT m.id, m.item_path, m.bangou, m.title, p.poster_path, p.poster_status, p.fanart_status FROM movies m JOIN pictures p ON m.id = p.movie_id WHERE p.poster_status = 'ä½ç”»è´¨' OR p.fanart_status = 'ä½ç”»è´¨' ORDER BY m.created_at DESC LIMIT ? OFFSET ?"
        items = conn.execute(query, (per_page, offset)).fetchall()
        total_query = "SELECT COUNT(m.id) FROM movies m JOIN pictures p ON m.id = p.movie_id WHERE p.poster_status = 'ä½ç”»è´¨' OR p.fanart_status = 'ä½ç”»è´¨'"
        total = conn.execute(total_query).fetchone()[0]
        conn.close()
        
        # æ¢å¤åŸå§‹çš„è¿”å›æ ¼å¼ï¼Œä¿æŒä¸å‰ç«¯çš„å…¼å®¹æ€§
        return jsonify({
            "items": [dict(row) for row in items], 
            "total": total, 
            "page": page, 
            "per_page": per_page, 
            "has_more": total > page * per_page
        })
    except Exception as e:
        current_app.logger.error(f"è·å–ä½ç”»è´¨é¡¹ç›®å¤±è´¥: {str(e)}", exc_info=True)
        return jsonify({"success": False, "message": f"è·å–ä½ç”»è´¨é¡¹ç›®å¤±è´¥: {str(e)}"}), 500

@api.route('/get-dmm-info', methods=['GET'])
def get_dmm_info():
    bangou = request.args.get('bangou')
    if not bangou: return jsonify({"success": False, "message": "éœ€è¦æä¾›ç•ªå·"}), 400
    api_url = current_app.config['CID_API_URL']
    api_key = current_app.config['CID_API_KEY']
    try:
        response = requests.get(api_url, params={'bangou': bangou}, headers={'X-API-KEY': api_key}, timeout=15)
        response.raise_for_status()
        cid_data = response.json()
        if not cid_data.get("success") or not cid_data.get("results"): return jsonify({"success": False, "message": "æœªæ‰¾åˆ°CID"}), 404
    except requests.RequestException as e: return jsonify({"success": False, "message": f"æŸ¥è¯¢CIDå¤±è´¥: {e}"}), 500
    results = []
    for res in cid_data.get("results", []):
        cid = res.get("cid")
        if not cid: continue
        parts = cid.split('00')
        code = parts[0] + parts[-1].zfill(5) if len(parts) > 1 else cid

        results.append({"cid": cid, "rule_info": res.get("rule_info"), "wallpaper_url": {"url": f"https://awsimgsrc.dmm.co.jp/pics_dig/digital/video/{code}/{code}pl.jpg"}, "cover_url": {"url": f"https://awsimgsrc.dmm.co.jp/pics_dig/digital/video/{code}/{code}ps.jpg"},})
    return jsonify({"success": True, "results": results})

def get_cached_verification(url):
    """ä»ç¼“å­˜ä¸­è·å–é“¾æ¥éªŒè¯ç»“æœ"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        # æŸ¥è¯¢ç¼“å­˜ï¼ˆæ°¸ä¹…æœ‰æ•ˆï¼Œé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        cursor.execute("""
            SELECT status_code, is_valid, cid
            FROM link_verification_cache
            WHERE url = ?
        """, (url,))

        result = cursor.fetchone()
        conn.close()

        if result:
            return {
                "url": url,
                "status_code": result[0],
                "valid": bool(result[1]),
                "cid": result[2]
            }
        return None
    except Exception as e:
        current_app.logger.error(f"è·å–ç¼“å­˜å¤±è´¥: {e}")
        return None

def cache_verification_result(url, status_code, is_valid, cid=None):
    """ç¼“å­˜é“¾æ¥éªŒè¯ç»“æœï¼ˆæ°¸ä¹…æœ‰æ•ˆï¼‰"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        cursor.execute("""
            INSERT OR REPLACE INTO link_verification_cache
            (url, cid, status_code, is_valid, verified_at)
            VALUES (?, ?, ?, ?, datetime('now'))
        """, (url, cid, status_code, is_valid))

        conn.commit()
        conn.close()

    except Exception as e:
        current_app.logger.error(f"ç¼“å­˜éªŒè¯ç»“æœå¤±è´¥: {e}")

@api.route('/clear-link-cache', methods=['POST'])
def clear_link_cache():
    """æ¸…é™¤é“¾æ¥éªŒè¯ç¼“å­˜"""
    try:
        data = request.get_json()
        if data and 'url' in data:
            # æ¸…é™¤ç‰¹å®šURLçš„ç¼“å­˜
            url = data['url']
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("DELETE FROM link_verification_cache WHERE url = ?", (url,))
            conn.commit()
            conn.close()
            return jsonify({"success": True, "message": f"å·²æ¸…é™¤ {url} çš„ç¼“å­˜"})
        else:
            # æ¸…é™¤æ‰€æœ‰ç¼“å­˜
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute("DELETE FROM link_verification_cache")
            conn.commit()
            conn.close()

            # åŒæ—¶æ¸…é™¤DMMåŸŸåç¼“å­˜
            global _dmm_domain_cache
            _dmm_domain_cache['status'] = None
            _dmm_domain_cache['last_check'] = None

            return jsonify({"success": True, "message": "å·²æ¸…é™¤æ‰€æœ‰é“¾æ¥éªŒè¯ç¼“å­˜å’ŒDMMåŸŸåç¼“å­˜"})
    except Exception as e:
        current_app.logger.error(f"æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")
        return jsonify({"success": False, "message": f"æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}"}), 500

@api.route('/clear-dmm-domain-cache', methods=['POST'])
def clear_dmm_domain_cache():
    """æ¸…é™¤DMMåŸŸåç¼“å­˜"""
    try:
        global _dmm_domain_cache
        _dmm_domain_cache['status'] = None
        _dmm_domain_cache['last_check'] = None

        return jsonify({
            "success": True,
            "message": "å·²æ¸…é™¤DMMåŸŸåç¼“å­˜"
        })
    except Exception as e:
        current_app.logger.error(f"æ¸…é™¤DMMåŸŸåç¼“å­˜å¤±è´¥: {e}")
        return jsonify({"success": False, "message": f"æ¸…é™¤DMMåŸŸåç¼“å­˜å¤±è´¥: {e}"}), 500

@api.route('/verify-links', methods=['POST'])
def verify_links():
    """
    æ‰¹é‡éªŒè¯é“¾æ¥æœ‰æ•ˆæ€§
    æ¥æ”¶é“¾æ¥æ•°ç»„ï¼Œè¿”å›æ¯ä¸ªé“¾æ¥çš„éªŒè¯çŠ¶æ€
    æ”¯æŒå¼ºåˆ¶åˆ·æ–°ç¼“å­˜
    """
    try:
        data = request.get_json()
        if not data or 'links' not in data:
            return jsonify({"success": False, "message": "éœ€è¦æä¾›linksæ•°ç»„"}), 400

        links = data['links']
        force_refresh = data.get('force_refresh', False)  # æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
        cid = data.get('cid')  # å¯é€‰çš„CIDå‚æ•°

        if not isinstance(links, list):
            return jsonify({"success": False, "message": "linkså¿…é¡»æ˜¯æ•°ç»„"}), 400

        def verify_single_link(url):
            """éªŒè¯å•ä¸ªé“¾æ¥çš„æœ‰æ•ˆæ€§ï¼Œæ”¯æŒHTTPç¼“å­˜åå•†å’ŒDMMåŸŸåç¼“å­˜"""



            # DMMåŸŸåä¼˜åŒ–ï¼šå¦‚æœæ˜¯DMMé“¾æ¥ä¸”åŸŸåä¸å¯ç”¨ï¼Œç›´æ¥è¿”å›å¤±è´¥
            if is_dmm_url(url) and not check_dmm_domain_availability():
                current_app.logger.debug(f"ğŸš« DMMåŸŸåä¸å¯ç”¨ï¼Œè·³è¿‡éªŒè¯: {url}")
                return {
                    "url": url,
                    "status_code": 0,
                    "valid": False,
                    "error": "DMMåŸŸåä¸å¯ç”¨"
                }

            # æ£€æŸ¥ç¼“å­˜ï¼Œè·å–ä¹‹å‰çš„ç¼“å­˜åå•†å¤´
            cached_result = get_cached_verification(url)

            if not force_refresh and cached_result:
                # å¦‚æœä¸æ˜¯å¼ºåˆ¶åˆ·æ–°ä¸”æœ‰ç¼“å­˜ï¼Œç›´æ¥è¿”å›ï¼ˆæ°¸ä¹…æœ‰æ•ˆï¼‰
                return cached_result

            try:
                try:
                    # ä½¿ç”¨4ç§’è¶…æ—¶ï¼Œé€‚åˆDMMæœåŠ¡å™¨
                    timeout = 4

                    # ä½¿ç”¨æ›´å®Œæ•´çš„æµè§ˆå™¨è¯·æ±‚å¤´
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0',
                        'Accept': 'image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'Referer': 'https://www.dmm.co.jp/'
                    }



                    # ä½¿ç”¨GETè¯·æ±‚ï¼Œstream=Falseæé«˜ç¨³å®šæ€§
                    response = _http_session.get(url, timeout=timeout, headers=headers, allow_redirects=True, stream=False)
                    status_code = response.status_code



                except requests.exceptions.Timeout as timeout_e:
                    current_app.logger.error(f"â° è¯·æ±‚è¶…æ—¶: {timeout_e}")
                    raise timeout_e
                except requests.exceptions.ConnectionError as conn_e:
                    current_app.logger.error(f"ğŸŒ è¿æ¥é”™è¯¯: {conn_e}")
                    raise conn_e
                except requests.exceptions.RequestException as req_e:
                    current_app.logger.error(f"ï¿½ è¯·æ±‚å¼‚å¸¸: {req_e}")
                    raise req_e
                except Exception as general_e:
                    current_app.logger.error(f"ğŸ’¥ æœªçŸ¥å¼‚å¸¸: {general_e}")
                    import traceback
                    current_app.logger.error(f"ğŸ’¥ å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                    raise general_e

                # åˆ¤æ–­é“¾æ¥æ˜¯å¦æœ‰æ•ˆ
                is_valid = 200 <= status_code < 400

                result = {
                    "url": url,
                    "status_code": status_code,
                    "valid": is_valid
                }

                # ç¼“å­˜éªŒè¯ç»“æœï¼ˆæ°¸ä¹…æœ‰æ•ˆï¼‰
                cache_verification_result(url, status_code, is_valid, cid)

                return result
            except requests.exceptions.Timeout as e:
                current_app.logger.warning(f"â° è¯·æ±‚è¶…æ—¶ (4ç§’): {url} - {str(e)}")
                return {
                    "url": url,
                    "status_code": 408,
                    "valid": False,
                    "error": f"è¯·æ±‚è¶…æ—¶ (4ç§’): {str(e)}"
                }
            except requests.exceptions.SSLError as e:
                current_app.logger.error(f"ğŸ”’ SSLé”™è¯¯: {url} - {str(e)}")
                return {
                    "url": url,
                    "status_code": 0,
                    "valid": False,
                    "error": f"SSLé”™è¯¯: {str(e)}"
                }
            except requests.exceptions.ConnectionError as e:
                current_app.logger.error(f"ğŸŒ è¿æ¥é”™è¯¯: {url} - {str(e)}")
                return {
                    "url": url,
                    "status_code": 0,
                    "valid": False,
                    "error": f"è¿æ¥é”™è¯¯: {str(e)}"
                }
            except requests.exceptions.RequestException as e:
                current_app.logger.error(f"ğŸš« è¯·æ±‚å¼‚å¸¸: {url} - {str(e)}")
                return {
                    "url": url,
                    "status_code": 0,
                    "valid": False,
                    "error": f"è¯·æ±‚å¼‚å¸¸: {str(e)}"
                }
            except Exception as e:
                current_app.logger.error(f"ğŸ’¥ æœªçŸ¥å¼‚å¸¸: {url} - {str(e)}")
                import traceback
                current_app.logger.error(f"ğŸ’¥ å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                return {
                    "url": url,
                    "status_code": 0,
                    "valid": False,
                    "error": f"éªŒè¯å¤±è´¥: {str(e)}"
                }

        # å¹¶è¡ŒéªŒè¯æ‰€æœ‰é“¾æ¥ä»¥æé«˜é€Ÿåº¦
        import concurrent.futures

        results = []
        valid_links = []

        # é¢„å¤„ç†é“¾æ¥ï¼Œåˆ†ç¦»DMMå’ŒéDMMé“¾æ¥
        dmm_links = []
        other_links = []

        for link in links:
            url = None
            if isinstance(link, str):
                url = link
            elif isinstance(link, dict) and 'url' in link:
                url = link['url']
            else:
                results.append({
                    "url": str(link),
                    "status_code": 0,
                    "valid": False,
                    "error": "æ— æ•ˆçš„é“¾æ¥æ ¼å¼"
                })
                continue

            if is_dmm_url(url):
                dmm_links.append(url)
            else:
                other_links.append(url)

        valid_links = dmm_links + other_links

        # DMMåŸŸåæ‰¹é‡ä¼˜åŒ–ï¼šå¦‚æœDMMåŸŸåä¸å¯ç”¨ï¼Œæ‰¹é‡æ ‡è®°æ‰€æœ‰DMMé“¾æ¥ä¸ºå¤±è´¥
        if dmm_links and not check_dmm_domain_availability():
            current_app.logger.warning(f"ğŸš« DMMåŸŸåä¸å¯ç”¨ï¼Œæ‰¹é‡è·³è¿‡{len(dmm_links)}ä¸ªDMMé“¾æ¥")
            for url in dmm_links:
                results.append({
                    "url": url,
                    "status_code": 0,
                    "valid": False,
                    "error": "DMMåŸŸåä¸å¯ç”¨"
                })
            # åªéªŒè¯éDMMé“¾æ¥
            valid_links = other_links

        # å¹¶è¡ŒéªŒè¯é“¾æ¥
        if valid_links:
            # åœ¨ä¸»çº¿ç¨‹ä¸­è·å–åº”ç”¨å®ä¾‹
            app = current_app._get_current_object()

            # åˆ›å»ºä¸€ä¸ªåŒ…è£…å‡½æ•°ï¼Œåœ¨Flaskåº”ç”¨ä¸Šä¸‹æ–‡ä¸­æ‰§è¡ŒéªŒè¯
            def verify_with_context(url):
                try:
                    with app.app_context():
                        return verify_single_link(url)
                except Exception as e:
                    # ä½¿ç”¨app.loggerè€Œä¸æ˜¯current_app.logger
                    with app.app_context():
                        app.logger.error(f"éªŒè¯é“¾æ¥å¼‚å¸¸: {url} - {str(e)}")
                    return {
                        "url": url,
                        "status_code": 0,
                        "valid": False,
                        "error": f"éªŒè¯å¼‚å¸¸: {str(e)}"
                    }

            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡ŒéªŒè¯ï¼Œæœ€å¤§4ä¸ªå¹¶å‘
            with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                # æäº¤æ‰€æœ‰éªŒè¯ä»»åŠ¡
                future_to_url = {executor.submit(verify_with_context, url): url for url in valid_links}

                # æ”¶é›†ç»“æœï¼Œä¿æŒåŸå§‹é¡ºåº
                url_results = {}
                for future in concurrent.futures.as_completed(future_to_url):
                    url = future_to_url[future]
                    try:
                        result = future.result()
                        url_results[url] = result
                    except Exception as e:
                        # ä½¿ç”¨app.loggerè€Œä¸æ˜¯current_app.logger
                        with app.app_context():
                            app.logger.error(f"å¹¶è¡ŒéªŒè¯å¼‚å¸¸: {url} - {str(e)}")
                        url_results[url] = {
                            "url": url,
                            "status_code": 0,
                            "valid": False,
                            "error": f"å¹¶è¡ŒéªŒè¯å¼‚å¸¸: {str(e)}"
                        }

                # æŒ‰åŸå§‹é¡ºåºæ·»åŠ ç»“æœ
                for url in valid_links:
                    results.append(url_results[url])

        return jsonify({"success": True, "results": results})

    except Exception as e:
        current_app.logger.error(f"éªŒè¯é“¾æ¥æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        return jsonify({"success": False, "message": f"éªŒè¯é“¾æ¥å¤±è´¥: {e}"}), 500

def _update_db_pic_info(conn, movie_id, target_type, save_path):
    width, height, size_kb, status = image_processor.get_image_details(save_path)
    update_query = f"UPDATE pictures SET {target_type}_path = ?, {target_type}_width = ?, {target_type}_height = ?, {target_type}_size_kb = ?, {target_type}_status = ? WHERE movie_id = ?"
    conn.execute(update_query, (save_path, width, height, size_kb, status, movie_id))
    current_app.logger.info(f"DB Updated for {target_type}: {save_path}, Status: {status}")

@api.route('/process/poster', methods=['POST'])
def process_poster_route():
    data = request.json
    movie_id, image_url, watermarks, crop = data.get('item_id'), data.get('image_url'), data.get('watermarks', []), data.get('crop', False)
    if not image_url: return jsonify({"success": False, "message": "ç¼ºå°‘å‚æ•°"}), 400
    settings = get_settings()
    
    # å¤„ç†ä¿å­˜è·¯å¾„ - å¦‚æœæä¾›äº†base_pathï¼Œåˆ™ä½¿ç”¨å®ƒï¼Œå¦åˆ™å°è¯•ä»movie_idè·å–
    save_path = None
    if data.get('base_path'):
        save_path = f"{data.get('base_path')}-poster.jpg"
    elif movie_id:
        conn = get_db_connection()
        movie = conn.execute('SELECT item_path FROM movies WHERE id = ?', (movie_id,)).fetchone()
        if not movie: conn.close(); return jsonify({"success": False, "message": "é¡¹ç›®ä¸å­˜åœ¨"}), 404
        save_path = f"{os.path.splitext(movie['item_path'])[0]}-poster.jpg"
        conn.close()
    else:
        return jsonify({"success": False, "message": "ç¼ºå°‘ä¿å­˜è·¯å¾„ä¿¡æ¯"}), 400
    
    success, msg = image_processor.process_image_from_url(image_url, save_path, 'poster', settings, watermarks, crop_for_poster=crop)
    
    # å¦‚æœæˆåŠŸä¸”æœ‰movie_idï¼Œæ›´æ–°æ•°æ®åº“
    if success and movie_id:
        conn = get_db_connection()
        _update_db_pic_info(conn, movie_id, 'poster', save_path)
        conn.commit()
        conn.close()
    
    return jsonify({"success": success, "message": msg})

@api.route('/process/fanart-and-thumb', methods=['POST'])
def process_fanart_and_thumb_route():
    data = request.json
    movie_id, image_url, watermarks, crop_poster_flag = data.get('item_id'), data.get('image_url'), data.get('watermarks', []), data.get('crop_poster', False)
    if not image_url: return jsonify({"success": False, "message": "ç¼ºå°‘å‚æ•°"}), 400
    settings = get_settings()
    
    # å¤„ç†ä¿å­˜è·¯å¾„ - å¦‚æœæä¾›äº†base_pathï¼Œåˆ™ä½¿ç”¨å®ƒï¼Œå¦åˆ™å°è¯•ä»movie_idè·å–
    base_path = data.get('base_path')
    if not base_path and movie_id:
        conn = get_db_connection()
        movie = conn.execute('SELECT item_path FROM movies WHERE id = ?', (movie_id,)).fetchone()
        if not movie: conn.close(); return jsonify({"success": False, "message": "é¡¹ç›®ä¸å­˜åœ¨"}), 404
        base_path = os.path.splitext(movie['item_path'])[0]
        conn.close()
    
    if not base_path:
        return jsonify({"success": False, "message": "ç¼ºå°‘ä¿å­˜è·¯å¾„ä¿¡æ¯"}), 400
    
    fanart_path = f"{base_path}-fanart.jpg"
    fanart_success, _ = image_processor.process_image_from_url(image_url, fanart_path, 'fanart', settings, watermarks, crop_for_poster=False)
    
    thumb_path = f"{base_path}-thumb.jpg"
    thumb_success, _ = image_processor.process_image_from_url(image_url, thumb_path, 'thumb', settings, watermarks, crop_for_poster=False)
    
    if crop_poster_flag:
        poster_path = f"{base_path}-poster.jpg"
        poster_success, _ = image_processor.process_image_from_url(image_url, poster_path, 'poster', settings, watermarks, crop_for_poster=True)
    
    # å¦‚æœæœ‰movie_idï¼Œæ›´æ–°æ•°æ®åº“
    if movie_id:
        conn = get_db_connection()
        if fanart_success: _update_db_pic_info(conn, movie_id, 'fanart', fanart_path)
        if thumb_success: _update_db_pic_info(conn, movie_id, 'thumb', thumb_path)
        if crop_poster_flag and poster_success: _update_db_pic_info(conn, movie_id, 'poster', poster_path)
        conn.commit()
        conn.close()
    
    return jsonify({"success": True, "message": "å›¾ç‰‡å¤„ç†å®Œæˆ"})

@api.route('/skip-item/<int:item_id>', methods=['POST'])
def skip_item(item_id):
    conn = get_db_connection()
    pic = conn.execute("SELECT poster_status, fanart_status, thumb_status FROM pictures WHERE movie_id = ?", (item_id,)).fetchone()
    if not pic: conn.close(); return jsonify({"success": False, "message": "æœªæ‰¾åˆ°å›¾ç‰‡è®°å½•"}), 404
    updates = []
    if pic['poster_status'] != 'é«˜ç”»è´¨': updates.append("poster_status = 'NoHD'")
    if pic['fanart_status'] != 'é«˜ç”»è´¨': updates.append("fanart_status = 'NoHD'")
    if pic['thumb_status'] != 'é«˜ç”»è´¨': updates.append("thumb_status = 'NoHD'")
    if updates:
        query = f"UPDATE pictures SET {', '.join(updates)} WHERE movie_id = ?"
        conn.execute(query, (item_id,))
        conn.commit()
    conn.close()
    return jsonify({"success": True, "message": "å·²æ ‡è®°ä¸ºè·³è¿‡"})

@api.route('/refresh-item-images/<int:item_id>', methods=['POST'])
def refresh_item_images(item_id):
    conn = get_db_connection()
    movie = conn.execute('SELECT item_path FROM movies WHERE id = ?', (item_id,)).fetchone()
    if not movie: conn.close(); return jsonify({"success": False, "message": "é¡¹ç›®ä¸å­˜åœ¨"}), 404
    base_path = os.path.splitext(movie['item_path'])[0]
    p_w, p_h, p_s_kb, p_stat = image_processor.get_image_details(f"{base_path}-poster.jpg")
    f_w, f_h, f_s_kb, f_stat = image_processor.get_image_details(f"{base_path}-fanart.jpg")
    t_w, t_h, t_s_kb, t_stat = image_processor.get_image_details(f"{base_path}-thumb.jpg")
    conn.execute("UPDATE pictures SET poster_width=?, poster_height=?, poster_size_kb=?, poster_status=?, fanart_width=?, fanart_height=?, fanart_size_kb=?, fanart_status=?, thumb_width=?, thumb_height=?, thumb_size_kb=?, thumb_status=? WHERE movie_id = ?", (p_w, p_h, p_s_kb, p_stat, f_w, f_h, f_s_kb, f_stat, t_w, t_h, t_s_kb, t_stat, item_id))
    conn.commit()
    updated_pic = conn.execute("SELECT poster_status, fanart_status FROM pictures WHERE movie_id = ?", (item_id,)).fetchone()
    conn.close()
    return jsonify({"success": True, "message": "å›¾ç‰‡ä¿¡æ¯å·²åˆ·æ–°", "data": dict(updated_pic) if updated_pic else {}})

@api.route('/files/list', methods=['GET'])
def list_files():
    req_path = request.args.get('path', get_media_root())
    
    # å¤„ç†è¯·æ±‚è·¯å¾„
    if not req_path:
        req_path = get_media_root()
    
    # å®‰å…¨æ£€æŸ¥
    if not is_safe_path(req_path):
        current_app.logger.warning(f"æ‹’ç»è®¿é—®è·¯å¾„: {req_path}, åª’ä½“æ ¹è·¯å¾„: {get_media_root()}")
        return jsonify({"error": "ç¦æ­¢è®¿é—®çš„è·¯å¾„", "details": f"è¯·æ±‚è·¯å¾„: {req_path}, åª’ä½“æ ¹è·¯å¾„: {get_media_root()}"}), 403
    
    # ç¡®ä¿è·¯å¾„å­˜åœ¨
    if not os.path.exists(req_path):
        return jsonify({"error": "è·¯å¾„ä¸å­˜åœ¨", "path": req_path}), 404
    
    # ç¡®ä¿æ˜¯ç›®å½•
    if not os.path.isdir(req_path):
        return jsonify({"error": "ä¸æ˜¯æœ‰æ•ˆç›®å½•", "path": req_path}), 400
    
    # åˆ†é¡µå‚æ•°
    page = request.args.get('page', 1, type=int)
    page_size = request.args.get('page_size', 200, type=int)  # é»˜è®¤æ¯é¡µ200é¡¹
    
    # æ–‡ä»¶ç±»å‹ç­›é€‰
    file_types = request.args.get('file_types')
    file_type_filters = file_types.split(',') if file_types else None
    
    # æ·»åŠ ç®€å•æ¨¡å¼ï¼Œåªè¿”å›åŸºæœ¬ä¿¡æ¯ï¼Œä¸è·å–æ–‡ä»¶å¤§å°ç­‰è¯¦ç»†ä¿¡æ¯
    simple_mode = request.args.get('simple', 'false').lower() == 'true'
    
    try:
        # è®¾ç½®è¶…æ—¶ï¼Œé¿å…å¤§ç›®å½•å¤„ç†æ—¶é—´è¿‡é•¿
        import signal
        
        def timeout_handler(signum, frame):
            _ = signum, frame  # å¿½ç•¥æœªä½¿ç”¨çš„å‚æ•°
            raise TimeoutError("å¤„ç†ç›®å½•å†…å®¹è¶…æ—¶ï¼Œç›®å½•å¯èƒ½åŒ…å«å¤ªå¤šæ–‡ä»¶")
        
        # è®¾ç½®30ç§’è¶…æ—¶
        signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(30)
        
        try:
            # è·å–ç›®å½•å†…æ‰€æœ‰é¡¹
            all_names = os.listdir(req_path)
            
            # é‡ç½®è¶…æ—¶è®¡æ—¶å™¨
            signal.alarm(0)
        except TimeoutError as e:
            current_app.logger.warning(f"ç›®å½•åˆ—è¡¨è·å–è¶…æ—¶: {req_path}")
            return jsonify({"error": str(e)}), 504  # Gateway Timeout
        
        # åº”ç”¨ç­›é€‰å™¨
        if file_type_filters:
            filtered_names = []
            for name in all_names:
                ext = os.path.splitext(name)[1].lower()
                # å¦‚æœæ²¡æœ‰æ‰©å±•åä½†éœ€è¦æ˜¾ç¤ºç›®å½•
                if (not ext and os.path.isdir(os.path.join(req_path, name)) and 'dir' in file_type_filters) or \
                   (ext and ext[1:] in file_type_filters):
                    filtered_names.append(name)
            all_names = filtered_names
            
        # è®¡ç®—æ€»æ•°å’Œåˆ†é¡µ
        total_items = len(all_names)
        total_pages = (total_items + page_size - 1) // page_size
        
        # è·å–å½“å‰é¡µçš„æ–‡ä»¶å
        start_idx = (page - 1) * page_size
        end_idx = min(start_idx + page_size, total_items)
        page_items = all_names[start_idx:end_idx]
        
        # å¤„ç†å½“å‰é¡µçš„æ–‡ä»¶ä¿¡æ¯
        items = []
        
        # åœ¨ç®€å•æ¨¡å¼ä¸‹ï¼Œåªè·å–æœ€åŸºæœ¬çš„æ–‡ä»¶ä¿¡æ¯
        if simple_mode:
            for name in page_items:
                item_abs_path = os.path.join(req_path, name)
                try:
                    is_dir = os.path.isdir(item_abs_path)
                    items.append({
                        "name": name,
                        "path": item_abs_path,
                        "is_directory": is_dir,
                        "size": 0,  # ç®€å•æ¨¡å¼ä¸è·å–å¤§å°
                        "modified_at": 0  # ç®€å•æ¨¡å¼ä¸è·å–ä¿®æ”¹æ—¶é—´
                    })
                except (FileNotFoundError, PermissionError):
                    # è·³è¿‡æ— æƒé™æˆ–ä¸¢å¤±çš„æ–‡ä»¶
                    continue
        else:
            # æ ‡å‡†æ¨¡å¼ï¼Œè·å–æ›´å¤šæ–‡ä»¶è¯¦æƒ…
            for name in page_items:
                item_abs_path = os.path.join(req_path, name)
                try:
                    stat = os.stat(item_abs_path)
                    is_dir = os.path.isdir(item_abs_path)
                    
                    # å¯¹äºç›®å½•ï¼Œåªè·å–å¿…è¦ä¿¡æ¯ï¼Œä¸é€’å½’ç»Ÿè®¡å¤§å°
                    items.append({
                        "name": name,
                        "path": item_abs_path,
                        "is_directory": is_dir,
                        "size": 0 if is_dir else stat.st_size,
                        "modified_at": stat.st_mtime
                    })
                except (FileNotFoundError, PermissionError):
                    # è·³è¿‡æ— æƒé™æˆ–ä¸¢å¤±çš„æ–‡ä»¶
                    continue
                
        return jsonify({
            "items": items,
            "pagination": {
                "page": page,
                "page_size": page_size,
                "total_items": total_items,
                "total_pages": total_pages
            }
        })
    except FileNotFoundError:
        return jsonify({"error": "ç›®å½•æœªæ‰¾åˆ°"}), 404
    except PermissionError:
        return jsonify({"error": "æ²¡æœ‰æƒé™è®¿é—®è¯¥ç›®å½•"}), 403
    except TimeoutError as e:
        return jsonify({"error": str(e)}), 504  # Gateway Timeout
    except Exception as e:
        current_app.logger.error(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": str(e)}), 500
    finally:
        # ç¡®ä¿è¶…æ—¶ä¿¡å·è¢«é‡ç½®
        if 'signal' in locals():
            try:
                signal.alarm(0)
            except:
                pass

@api.route('/files/rename', methods=['POST'])
def rename_file():
    old_path, new_name = request.json.get('path'), request.json.get('new_name')
    if not all([old_path, new_name]) or not is_safe_path(old_path): return jsonify({"error": "æ— æ•ˆçš„è¯·æ±‚"}), 400
    new_path = os.path.join(os.path.dirname(old_path), new_name)
    if not is_safe_path(new_path): return jsonify({"error": "æ— æ•ˆçš„æ–°è·¯å¾„"}), 400
    try:
        success, error = safe_rename(old_path, new_path)
        if success:
            return jsonify({"success": True, "message": "é‡å‘½åæˆåŠŸ"})
        else:
            return jsonify({"error": error}), 500
    except Exception as e: return jsonify({"error": str(e)}), 500

@api.route('/files/delete', methods=['POST'])
def delete_files():
    paths = request.json.get('paths', [])
    if not paths: return jsonify({"error": "æ²¡æœ‰æä¾›è¦åˆ é™¤çš„è·¯å¾„"}), 400
    for path in paths:
        if not is_safe_path(path): return jsonify({"error": f"ç¦æ­¢åˆ é™¤è·¯å¾„: {path}"}), 403
        try:
            success, error = safe_delete(path)
            if not success:
                return jsonify({"error": error}), 500
        except Exception as e: return jsonify({"error": f"åˆ é™¤ {path} å¤±è´¥: {e}"}), 500
    return jsonify({"success": True, "message": "åˆ é™¤æˆåŠŸ"})

@api.route('/files/create-dir', methods=['POST'])
def create_directory():
    parent_path, name = request.json.get('path'), request.json.get('name')
    if not all([parent_path, name]) or not is_safe_path(parent_path): return jsonify({"error": "æ— æ•ˆçš„è¯·æ±‚"}), 400
    new_dir_path = os.path.join(parent_path, name)
    if not is_safe_path(new_dir_path): return jsonify({"error": "æ— æ•ˆçš„æ–°ç›®å½•è·¯å¾„"}), 400
    try:
        os.makedirs(new_dir_path, exist_ok=True)
        return jsonify({"success": True, "message": "ç›®å½•åˆ›å»ºæˆåŠŸ"})
    except Exception as e: return jsonify({"error": str(e)}), 500

@api.route('/manual/find-movie', methods=['GET'])
def find_movie_by_query():
    query = request.args.get('q', '').strip()
    if not query: return jsonify([])
    conn = get_db_connection()
    search_query = f"%{query}%"
    movies = conn.execute("SELECT id, bangou, title, item_path FROM movies WHERE bangou LIKE ? OR item_path LIKE ? LIMIT 10", (search_query, search_query)).fetchall()
    conn.close()
    return jsonify([dict(row) for row in movies])

@api.route('/manual/movie-details/<int:movie_id>', methods=['GET'])
def get_movie_details(movie_id):
    conn = get_db_connection()
    movie = conn.execute("SELECT * FROM movies WHERE id = ?", (movie_id,)).fetchone()
    if not movie: conn.close(); return jsonify({"error": "æœªæ‰¾åˆ°ç”µå½±"}), 404
    pictures = conn.execute("SELECT * FROM pictures WHERE movie_id = ?", (movie_id,)).fetchone()
    nfo_records = conn.execute("SELECT id, nfo_path FROM nfo_data WHERE movie_id = ?", (movie_id,)).fetchall()
    conn.close()
    return jsonify({"movie": dict(movie), "pictures": dict(pictures) if pictures else {}, "nfo_files": [dict(row) for row in nfo_records]})

# ä¿®æ”¹get_nfo_contentå‡½æ•°
@api.route('/manual/nfo-content/<int:nfo_id>', methods=['GET'])
def get_nfo_content(nfo_id):
    """è·å–æ•°æ®æ¸…æ´—æ¨¡å¼çš„NFOå†…å®¹"""
    conn = get_db_connection()
    nfo_record = conn.execute("SELECT nfo_path FROM nfo_data WHERE id = ?", (nfo_id,)).fetchone()
    conn.close()
    
    if not nfo_record: 
        return jsonify({"error": "æœªæ‰¾åˆ°NFOè®°å½•"}), 404
        
    nfo_path = nfo_record['nfo_path']
    if not is_safe_path(nfo_path): 
        return jsonify({"error": "æ— æ•ˆçš„NFOè·¯å¾„"}), 400
        
    try:
        # è§£æNFOæ–‡ä»¶
        nfo_data = parse_nfo_file(nfo_path)
        
        # ç¡®ä¿è¿”å›çš„æ˜¯å¯åºåˆ—åŒ–çš„æ•°æ®
        if nfo_data and '_nfo_path' in nfo_data:
            nfo_data.pop('_nfo_path', None)
            
        if not nfo_data:
            return jsonify({"error": "NFOæ–‡ä»¶è§£æå¤±è´¥"}), 500
            
        return jsonify(nfo_data)
    except Exception as e: 
        current_app.logger.error(f"è¯»å–NFOæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
        return jsonify({"error": f"è¯»å–NFOæ–‡ä»¶å¤±è´¥: {e}"}), 500

# ä¿®æ”¹save_nfo_contentå‡½æ•°
@api.route('/manual/save-nfo/<int:nfo_id>', methods=['POST'])
def save_nfo_content(nfo_id):
    """æ•°æ®æ¸…æ´—æ¨¡å¼ä¿å­˜NFOæ–‡ä»¶ï¼ŒåŒæ—¶æ›´æ–°æ•°æ®åº“"""
    data = request.json
    if not data:
        return jsonify({"success": False, "message": "è¯·æ±‚æ•°æ®ä¸ºç©º"}), 400
        
    conn = get_db_connection()
    
    try:
        # è·å–NFOè®°å½•
        nfo_record = conn.execute("SELECT nfo_path, strm_name FROM nfo_data WHERE id = ?", (nfo_id,)).fetchone()
        if not nfo_record:
            conn.close()
            return jsonify({"success": False, "message": "æœªæ‰¾åˆ°NFOè®°å½•"}), 404
            
        nfo_path = nfo_record['nfo_path']
        # ä¿®å¤: sqlite3.Rowå¯¹è±¡ä½¿ç”¨ç´¢å¼•æ–¹å¼è®¿é—®ï¼Œä¸è¦ç”¨.get()æ–¹æ³•
        # å¦‚æœstrm_nameä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²ä½œä¸ºé»˜è®¤å€¼
        strm_name = nfo_record['strm_name'] if 'strm_name' in nfo_record.keys() else ''
        
        if not is_safe_path(nfo_path):
            conn.close()
            return jsonify({"success": False, "message": "æ— æ•ˆçš„NFOè·¯å¾„"}), 400
            
        # å¤„ç†æ ‡é¢˜å’ŒåŸå§‹æ ‡é¢˜ï¼Œä»æ•°æ®åº“è§’åº¦éœ€è¦æ‹¼æ¥ç•ªå·ï¼Œä½†åœ¨NFOä¸­å·²ç”±save_nfo_fileå¤„ç†
        from nfo_parser import extract_bangou_from_title, save_nfo_file
        
        # ä¿å­˜åˆ°NFOæ–‡ä»¶ï¼Œä½¿ç”¨'database'æ¨¡å¼ï¼Œç¡®ä¿é€‚å½“å¤„ç†ç•ªå·
        success, message = save_nfo_file(nfo_path, data, mode='database')
        if not success:
            conn.close()
            return jsonify({"success": False, "message": message}), 500
            
        # å¤„ç†æ•°æ®åº“æ›´æ–°
        # ä¸ºæ•°æ®åº“ä¸­çš„å­—æ®µå¤„ç†ï¼šæå–æ ‡é¢˜ä¸­çš„ç•ªå·å¹¶æ¸…ç†
        _, clean_title = extract_bangou_from_title(data.get('title', ''))
        if 'title' in data:
            data['title'] = clean_title
            
        # åŒæ ·å¤„ç†originaltitle
        if 'originaltitle' in data:
            _, clean_orig_title = extract_bangou_from_title(data.get('originaltitle', ''))
            data['originaltitle'] = clean_orig_title
        
        # æ›´æ–°æ•°æ®åº“ä¸­çš„NFOè®°å½•
        nfo_main_cols = ['originaltitle', 'plot', 'originalplot', 'tagline', 'release_date', 'year', 'rating', 'criticrating']
        nfo_main_vals = [data.get(col) for col in nfo_main_cols]
        
        # ä»…æ›´æ–°å­˜åœ¨çš„å­—æ®µ
        update_cols = []
        update_vals = []
        
        for i, col in enumerate(nfo_main_cols):
            if col in data:
                update_cols.append(f"{col}=?")
                update_vals.append(nfo_main_vals[i])
                
        if update_cols:
            conn.execute(f"UPDATE nfo_data SET {', '.join(update_cols)} WHERE id = ?", (*update_vals, nfo_id))
        
        # å¤„ç†ç›¸å…³æ˜ å°„ï¼ˆæ¼”å‘˜ã€ç±»å‹ç­‰ï¼‰
        from webhook_handler import handle_nfo_mappings
        handle_nfo_mappings(conn.cursor(), nfo_id, data)
        
        conn.commit()
        return jsonify({"success": True, "message": "NFO å·²æˆåŠŸä¿å­˜å¹¶æ›´æ–°æ•°æ®åº“"})
    except Exception as e:
        conn.rollback()
        current_app.logger.error(f"ä¿å­˜NFOå¤±è´¥: {e}", exc_info=True)
        return jsonify({"success": False, "message": f"ä¿å­˜å¤±è´¥: {e}"}), 500
    finally:
        conn.close()

# ä¿®æ”¹get_handmade_nfo_detailså‡½æ•°
@api.route('/handmade/nfo-details', methods=['GET'])
def get_handmade_nfo_details():
    """è·å–æ‰‹ä½œä¿®æ­£æ¨¡å¼çš„NFOè¯¦æƒ…"""
    nfo_path = request.args.get('path')
    if not nfo_path or not is_safe_path(nfo_path): 
        return jsonify({"error": "æ— æ•ˆçš„NFOè·¯å¾„"}), 400
        
    base_path = os.path.splitext(nfo_path)[0]
    poster_info = image_processor.get_image_details(f"{base_path}-poster.jpg")
    fanart_info = image_processor.get_image_details(f"{base_path}-fanart.jpg")
    thumb_info = image_processor.get_image_details(f"{base_path}-thumb.jpg")
    pictures = {
        "poster_path": f"{base_path}-poster.jpg", "poster_stats": poster_info,
        "fanart_path": f"{base_path}-fanart.jpg", "fanart_stats": fanart_info,
        "thumb_path": f"{base_path}-thumb.jpg", "thumb_stats": thumb_info,
    }
    
    # ä½¿ç”¨ä¿®æ”¹åçš„NFOè§£æå™¨è·å–æ•°æ®
    nfo_data = parse_nfo_file(nfo_path)
    
    # ç¡®ä¿è¿”å›çš„æ˜¯å¯åºåˆ—åŒ–çš„æ•°æ®
    if nfo_data and '_nfo_path' in nfo_data:
        # ä¸éœ€è¦åœ¨JSONä¸­ä¼ é€’å†…éƒ¨å­—æ®µ
        nfo_data.pop('_nfo_path', None)
        
    return jsonify({"pictures": pictures, "nfo_data": nfo_data})

# ä¿®æ”¹save_handmade_nfoå‡½æ•°
@api.route('/handmade/save-nfo', methods=['POST'])
def save_handmade_nfo():
    """æ‰‹ä½œä¿®æ­£æ¨¡å¼ä¿å­˜NFOæ–‡ä»¶"""
    nfo_path = request.args.get('path')
    if not nfo_path or not is_safe_path(nfo_path):
        return jsonify({"success": False, "message": "æ— æ•ˆçš„NFOè·¯å¾„"}), 400
    
    try:
        data = request.json
        if not data:
            return jsonify({"success": False, "message": "è¯·æ±‚æ•°æ®ä¸ºç©º"}), 400
            
        from nfo_parser import save_nfo_file
        
        # ä½¿ç”¨'handmade'æ¨¡å¼ï¼Œä»…ä¿®æ”¹NFOæ–‡ä»¶ï¼Œä¸æ›´æ–°æ•°æ®åº“
        success, message = save_nfo_file(nfo_path, data, mode='handmade')
        
        if success:
            return jsonify({"success": True, "message": "NFOæ–‡ä»¶ä¿å­˜æˆåŠŸ"})
        else:
            return jsonify({"success": False, "message": message}), 500
    except Exception as e:
        current_app.logger.error(f"ä¿å­˜NFOæ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
        return jsonify({"success": False, "message": f"ä¿å­˜NFOæ–‡ä»¶å¤±è´¥: {e}"}), 500

@api.route('/process/upload-image', methods=['POST'])
def upload_and_process_image():
    """
    å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡ï¼Œæ·»åŠ æ°´å°å¹¶è¿”å›å¤„ç†åçš„å›¾ç‰‡
    å¯ä»¥é€‰æ‹©ç›´æ¥ä¿å­˜åˆ°ç‰¹å®šè·¯å¾„
    """
    if 'image' not in request.files:
        return jsonify({"success": False, "message": "æ²¡æœ‰ä¸Šä¼ å›¾ç‰‡"}), 400
    
    image_file = request.files['image']
    if image_file.filename == '':
        return jsonify({"success": False, "message": "æœªé€‰æ‹©å›¾ç‰‡"}), 400

    # å¤„ç†å‚æ•°
    watermarks = request.form.getlist('watermarks[]') if 'watermarks[]' in request.form else []
    target_type = request.form.get('target_type', 'preview')  # 'preview', 'poster', 'fanart', 'thumb'
    crop_for_poster = request.form.get('crop_for_poster', 'false').lower() == 'true'
    save_path = request.form.get('save_path', '')
    
    # ä¿å­˜ä¸Šä¼ çš„å›¾ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_dir = tempfile.mkdtemp()
    try:
        temp_path = os.path.join(temp_dir, secure_filename(image_file.filename))
        image_file.save(temp_path)
        
        settings = get_settings()
        
        if target_type == 'preview':
            # å¤„ç†é¢„è§ˆæ¨¡å¼ - è¿”å›å¤„ç†åçš„å›¾ç‰‡ï¼Œä½†ä¸ä¿å­˜
            output_temp = os.path.join(temp_dir, f"preview_{uuid.uuid4().hex}.jpg")
            with open(temp_path, 'rb') as f:
                img = image_processor.Image.open(f).convert("RGB")
                
                if crop_for_poster:
                    crop_ratio = float(settings.get('poster_crop_ratio', 1.419))
                    target_ratio = 1 / crop_ratio
                    current_ratio = img.width / img.height
                    if current_ratio > target_ratio:
                        new_width = int(target_ratio * img.height)
                        left = img.width - new_width
                        img = img.crop((left, 0, img.width, img.height))
                
                # åªæœ‰åœ¨é¢„è§ˆæ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬æ€»æ˜¯åº”ç”¨æ°´å°
                img = image_processor.add_watermarks(img, watermarks, settings)
                img.save(output_temp, "JPEG", quality=95)
            
            # è®¾ç½®å“åº”ç±»å‹ä¸ºå›¾ç‰‡
            return send_from_directory(os.path.dirname(output_temp), 
                                      os.path.basename(output_temp), 
                                      as_attachment=True,
                                      mimetype='image/jpeg')
        else:
            # ä¿å­˜æ¨¡å¼ - å¤„ç†å¹¶ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
            if not save_path:
                return jsonify({"success": False, "message": "æœªæŒ‡å®šä¿å­˜è·¯å¾„"}), 400
                
            if not is_safe_path(save_path):
                return jsonify({"success": False, "message": "æ— æ•ˆçš„ä¿å­˜è·¯å¾„"}), 403
                
            success, msg = image_processor.process_image_from_url(
                f"file://{temp_path}", save_path, target_type, settings, watermarks, crop_for_poster
            )
            
            # å¦‚æœæ˜¯é’ˆå¯¹ç‰¹å®šmovie_idçš„ï¼Œæ›´æ–°æ•°æ®åº“
            movie_id = request.form.get('movie_id')
            if success and movie_id and movie_id.isdigit():
                conn = get_db_connection()
                try:
                    _update_db_pic_info(conn, int(movie_id), target_type, save_path)
                    conn.commit()
                finally:
                    conn.close()
                    
            return jsonify({"success": success, "message": msg})
    
    except Exception as e:
        current_app.logger.error(f"å¤„ç†ä¸Šä¼ å›¾ç‰‡å¤±è´¥: {e}", exc_info=True)
        return jsonify({"success": False, "message": f"å¤„ç†å¤±è´¥: {e}"}), 500
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        shutil.rmtree(temp_dir, ignore_errors=True)

# æ·»åŠ æ—¥å¿—ç®¡ç†ç›¸å…³çš„è·¯ç”±
@api.route('/system-logs', methods=['GET'])
def get_system_logs():
    """è·å–ç³»ç»Ÿæ—¥å¿—æ–‡ä»¶å†…å®¹"""
    try:
        log_file_path = os.path.join('logs', 'app.log')
        if not os.path.exists(log_file_path):
            return jsonify({"success": False, "message": "æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨"}), 404
            
        # è·å–æŸ¥è¯¢å‚æ•°
        max_lines = request.args.get('max_lines', 500, type=int)
        log_level = request.args.get('level', '').upper()  # å¯é€‰çš„æ—¥å¿—çº§åˆ«ç­›é€‰
        
        # è¯»å–æ—¥å¿—æ–‡ä»¶
        with open(log_file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # å¦‚æœè®¾ç½®äº†æ—¥å¿—çº§åˆ«è¿‡æ»¤ï¼Œåˆ™åªè¿”å›åŒ¹é…çš„è¡Œ
        if log_level:
            lines = [line for line in lines if f' {log_level}' in line or f' {log_level}:' in line]
        
        # è¿”å›æœ€åçš„max_linesè¡Œ
        logs = lines[-max_lines:] if len(lines) > max_lines else lines
        
        # è§£ææ—¥å¿—è¡Œï¼Œæå–æ—¶é—´ã€çº§åˆ«ã€çº¿ç¨‹å’Œå†…å®¹
        parsed_logs = []
        for line in logs:
            try:
                # æ ‡å‡†æ—¥å¿—æ ¼å¼é€šå¸¸æ˜¯: 2025-07-24 12:33:05,219 INFO: æ¶ˆæ¯å†…å®¹ [in /app/db_manager.py:176]
                line = line.strip()
                
                # é¦–å…ˆå°è¯•åˆ†ç¦»æ—¶é—´æˆ³
                timestamp_match = re.match(r'^(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2},\d{3})\s+(.+)$', line)
                if timestamp_match:
                    timestamp = timestamp_match.group(1)
                    content = timestamp_match.group(2)
                else:
                    timestamp = ""
                    content = line
                
                # ç„¶åå°è¯•åˆ†ç¦»æ—¥å¿—çº§åˆ«
                level_match = re.match(r'^(DEBUG|INFO|WARNING|ERROR|CRITICAL):\s+(.+)$', content)
                if level_match:
                    level = level_match.group(1)
                    content = level_match.group(2)
                else:
                    # å¯èƒ½æ˜¯å…¶ä»–æ ¼å¼ï¼Œå¦‚"INFO æ¶ˆæ¯å†…å®¹"
                    alt_level_match = re.match(r'^(DEBUG|INFO|WARNING|ERROR|CRITICAL)\s+(.+)$', content)
                    if alt_level_match:
                        level = alt_level_match.group(1)
                        content = alt_level_match.group(2)
                    else:
                        level = ""
                
                # æœ€åæå–çº¿ç¨‹ä¿¡æ¯ï¼Œé€šå¸¸åœ¨æ¶ˆæ¯æœ«å°¾ [in /path/file.py:line]
                thread_match = re.search(r'\[in\s+([^\]]+)\]$', content)
                if thread_match:
                    thread = thread_match.group(1)
                    # ä»æ¶ˆæ¯ä¸­ç§»é™¤çº¿ç¨‹ä¿¡æ¯
                    content = content.replace(f'[in {thread}]', '').strip()
                else:
                    thread = ""
                
                parsed_logs.append({
                    'timestamp': timestamp,
                    'level': level,
                    'thread': thread,
                    'message': content
                })
            except Exception as e:
                # å¦‚æœè§£æå¤±è´¥ï¼Œåˆ™æ·»åŠ åŸå§‹è¡Œ
                current_app.logger.error(f"è§£ææ—¥å¿—è¡Œå¤±è´¥: {str(e)}, è¡Œ: {line}")
                parsed_logs.append({
                    'timestamp': '',
                    'level': '',
                    'thread': '',
                    'message': line
                })
                
        return jsonify({
            "success": True, 
            "logs": parsed_logs,
            "total_lines": len(lines)
        })
    except Exception as e:
        current_app.logger.error(f"è·å–ç³»ç»Ÿæ—¥å¿—å¤±è´¥: {str(e)}", exc_info=True)
        return jsonify({"success": False, "message": f"è·å–ç³»ç»Ÿæ—¥å¿—å¤±è´¥: {str(e)}"}), 500

@api.route('/system-logs/clear', methods=['POST'])
def clear_system_logs():
    """æ¸…ç©ºç³»ç»Ÿæ—¥å¿—æ–‡ä»¶"""
    try:
        log_file_path = os.path.join('logs', 'app.log')
        if os.path.exists(log_file_path):
            # æ‰“å¼€æ–‡ä»¶å¹¶æˆªæ–­ä¸ºç©º
            with open(log_file_path, 'w') as f:
                f.write('')
            current_app.logger.info("ç³»ç»Ÿæ—¥å¿—å·²è¢«ç®¡ç†å‘˜æ¸…é™¤")
            return jsonify({"success": True, "message": "æ—¥å¿—å·²æ¸…é™¤"})
        else:
            return jsonify({"success": False, "message": "æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨"}), 404
    except Exception as e:
        current_app.logger.error(f"æ¸…é™¤ç³»ç»Ÿæ—¥å¿—å¤±è´¥: {str(e)}", exc_info=True)
        return jsonify({"success": False, "message": f"æ¸…é™¤ç³»ç»Ÿæ—¥å¿—å¤±è´¥: {str(e)}"}), 500

@api.route('/update-log-level', methods=['POST'])
def update_log_level():
    """æ›´æ–°æ—¥å¿—çº§åˆ«"""
    try:
        data = request.json
        log_level = data.get('log_level', 'INFO').upper()
        
        # éªŒè¯æ—¥å¿—çº§åˆ«æ˜¯å¦æœ‰æ•ˆ
        if log_level not in ['DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL']:
            return jsonify({"success": False, "message": "æ— æ•ˆçš„æ—¥å¿—çº§åˆ«"}), 400
        
        # è·å–å½“å‰è®¾ç½®
        settings = get_settings()
        
        # æ›´æ–°æ—¥å¿—çº§åˆ«
        settings['log_level'] = log_level
        success, message, restart_needed = save_settings(settings)
        
        if success:
            # æ›´æ–°å½“å‰åº”ç”¨çš„æ—¥å¿—çº§åˆ«
            new_level = getattr(logging, log_level, logging.INFO)
            current_app.logger.setLevel(new_level)
            for handler in current_app.logger.handlers:
                handler.setLevel(new_level)
            
            current_app.logger.info(f"æ—¥å¿—çº§åˆ«å·²æ›´æ–°ä¸º: {log_level}")
            return jsonify({"success": True, "message": f"æ—¥å¿—çº§åˆ«å·²æ›´æ–°ä¸º: {log_level}"})
        else:
            return jsonify({"success": False, "message": message}), 500
    except Exception as e:
        current_app.logger.error(f"æ›´æ–°æ—¥å¿—çº§åˆ«å¤±è´¥: {str(e)}", exc_info=True)
        return jsonify({"success": False, "message": f"æ›´æ–°æ—¥å¿—çº§åˆ«å¤±è´¥: {str(e)}"}), 500

# æ·»åŠ å°é¢ç¼“å­˜ç®¡ç†APIç«¯ç‚¹
@api.route('/cover-cache', methods=['GET'])
def get_cover_cache_status():
    """è·å–å°é¢ç¼“å­˜çŠ¶æ€"""
    try:
        cache_dir = get_cover_cache_dir()
        if not os.path.exists(cache_dir):
            return jsonify({"success": False, "message": "ç¼“å­˜ç›®å½•ä¸å­˜åœ¨"}), 404
        
        # è·å–æ‰€æœ‰ç¼“å­˜çš„å°é¢æ–‡ä»¶
        covers = []
        total_size = 0
        for filename in os.listdir(cache_dir):
            if filename.endswith('.jpg'):
                file_path = os.path.join(cache_dir, filename)
                file_size = os.path.getsize(file_path) / 1024  # è½¬æ¢ä¸ºKB
                total_size += file_size
                covers.append({
                    "filename": filename,
                    "path": file_path,
                    "size_kb": round(file_size, 2),
                    "modified_at": os.path.getmtime(file_path)
                })
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        covers.sort(key=lambda x: x['modified_at'], reverse=True)
        
        settings = get_settings()
        max_covers = settings.get('latest_movies_count', 24)
        
        return jsonify({
            "success": True, 
            "cache_dir": cache_dir,
            "total_files": len(covers),
            "total_size_kb": round(total_size, 2),
            "max_covers": max_covers,
            "covers": covers
        })
    except Exception as e:
        current_app.logger.error(f"è·å–å°é¢ç¼“å­˜çŠ¶æ€å¤±è´¥: {str(e)}", exc_info=True)
        return jsonify({"success": False, "message": f"è·å–å°é¢ç¼“å­˜çŠ¶æ€å¤±è´¥: {str(e)}"}), 500

@api.route('/cover-cache/refresh', methods=['POST'])
def refresh_cover_cache():
    """åˆ·æ–°å°é¢ç¼“å­˜"""
    try:
        settings = get_settings()
        count = settings.get('latest_movies_count', 24)
        
        # è·å–æœ€æ–°çš„é«˜ç”»è´¨é¡¹ç›®
        items = _get_latest_high_quality_items(count)
        
        # æ¸…ç†ç°æœ‰ç¼“å­˜
        cache_dir = get_cover_cache_dir()
        deleted_count = 0
        if os.path.isdir(cache_dir):
            for filename in os.listdir(cache_dir):
                if filename.endswith('.jpg'):
                    try:
                        os.remove(os.path.join(cache_dir, filename))
                        deleted_count += 1
                    except Exception as e:
                        current_app.logger.error(f"åˆ é™¤ç¼“å­˜æ–‡ä»¶å¤±è´¥: {filename}, é”™è¯¯: {str(e)}")
        
        if deleted_count > 0:
            current_app.logger.info(f"å·²æ¸…ç†æ—§ç¼“å­˜: åˆ é™¤äº†{deleted_count}ä¸ªæ–‡ä»¶")
        
        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        os.makedirs(cache_dir, exist_ok=True)
        
        # åˆ›å»ºæ–°çš„ç¼“å­˜
        cache_count = 0
        for item in items:
            strm_name = item['strm_name']
            poster_path = item['poster_path']
            if strm_name and poster_path:
                if copy_to_cover_cache(poster_path, strm_name):
                    cache_count += 1
        
        return jsonify({
            "success": True,
            "message": f"å°é¢ç¼“å­˜åˆ·æ–°æˆåŠŸï¼Œå·²ç¼“å­˜ {cache_count} ä¸ªå°é¢",
            "cache_count": cache_count
        })
    except Exception as e:
        current_app.logger.error(f"åˆ·æ–°å°é¢ç¼“å­˜å¤±è´¥: {str(e)}", exc_info=True)
        return jsonify({"success": False, "message": f"åˆ·æ–°å°é¢ç¼“å­˜å¤±è´¥: {str(e)}"}), 500

@api.route('/cover-cache/clean', methods=['POST'])
def clean_cover_cache_route():
    """æ¸…ç†å°é¢ç¼“å­˜"""
    try:
        settings = get_settings()
        max_covers = settings.get('latest_movies_count', 24)
        clean_cover_cache(max_covers)
        return jsonify({"success": True, "message": f"å·²æ¸…ç†å¤šä½™çš„å°é¢ç¼“å­˜ï¼Œä¿ç•™æœ€æ–°çš„ {max_covers} ä¸ª"})
    except Exception as e:
        current_app.logger.error(f"æ¸…ç†å°é¢ç¼“å­˜å¤±è´¥: {str(e)}", exc_info=True)
        return jsonify({"success": False, "message": f"æ¸…ç†å°é¢ç¼“å­˜å¤±è´¥: {str(e)}"}), 500

@api.route('/restart-container', methods=['POST'])
def restart_container():
    """é‡å¯å®¹å™¨å†…çš„æœåŠ¡"""
    try:
        current_app.logger.info("æ”¶åˆ°é‡å¯å®¹å™¨è¯·æ±‚")
        
        # æ–¹æ³•1: å‘é€ä¿¡å·ç»™supervisorä¸»è¿›ç¨‹é‡å¯æ‰€æœ‰æœåŠ¡
        try:
            current_app.logger.info("å°è¯•å‘supervisorå‘é€é‡å¯ä¿¡å·")
            
            # æŸ¥æ‰¾supervisorä¸»è¿›ç¨‹PID
            with open("/var/run/supervisord.pid", 'r') as f:
                supervisor_pid = int(f.read().strip())
            
            # å‘é€SIGHUPä¿¡å·é‡æ–°åŠ è½½é…ç½®å¹¶é‡å¯æœåŠ¡
            os.kill(supervisor_pid, signal.SIGHUP)
            
            current_app.logger.info(f"=== æœåŠ¡é‡å¯æˆåŠŸ ===")
            current_app.logger.info(f"å·²å‘supervisorè¿›ç¨‹({supervisor_pid})å‘é€SIGHUPä¿¡å·")
            return jsonify({
                "success": True,
                "message": "æœåŠ¡æ­£åœ¨é‡å¯ï¼Œè¯·ç¨ååˆ·æ–°é¡µé¢"
            })
            
        except Exception as e:
            current_app.logger.warning(f"å‘supervisorå‘é€ä¿¡å·å¤±è´¥: {e}")
        
        # æ–¹æ³•2: åˆ›å»ºé‡å¯è„šæœ¬å¼‚æ­¥æ‰§è¡Œ
        try:
            current_app.logger.info("å°è¯•ä½¿ç”¨é‡å¯è„šæœ¬")
            
            # åˆ›å»ºé‡å¯è„šæœ¬ï¼Œç›´æ¥æ€æ­»å½“å‰è¿›ç¨‹è®©supervisoré‡å¯
            restart_script = """#!/bin/bash
sleep 2
# æ€æ­»gunicornä¸»è¿›ç¨‹ï¼Œsupervisorä¼šè‡ªåŠ¨é‡å¯
pkill -f "gunicorn.*app:app" || true
# æ€æ­»schedulerè¿›ç¨‹ï¼Œsupervisorä¼šè‡ªåŠ¨é‡å¯  
pkill -f "scheduler_standalone.py" || true
"""
            script_path = "/tmp/restart_services.sh"
            with open(script_path, 'w') as f:
                f.write(restart_script)
            os.chmod(script_path, 0o755)
            
            # å¼‚æ­¥æ‰§è¡Œé‡å¯è„šæœ¬
            subprocess.Popen(["/bin/bash", script_path], 
                           stdout=subprocess.DEVNULL, 
                           stderr=subprocess.DEVNULL)
            
            return jsonify({
                "success": True,
                "message": "æœåŠ¡æ­£åœ¨é‡å¯ï¼Œè¯·ç¨ååˆ·æ–°é¡µé¢"
            })
            
        except Exception as e:
            current_app.logger.warning(f"é‡å¯è„šæœ¬æ‰§è¡Œå¤±è´¥: {e}")
        
        # æ–¹æ³•3: ç›´æ¥é€€å‡ºå½“å‰è¿›ç¨‹ï¼Œè®©supervisorè‡ªåŠ¨é‡å¯
        try:
            current_app.logger.info("ä½¿ç”¨è¿›ç¨‹é€€å‡ºæ–¹å¼è§¦å‘é‡å¯")
            
            def delayed_exit():
                time.sleep(2)
                current_app.logger.info("æ‰§è¡Œè¿›ç¨‹é€€å‡º")
                os._exit(1)  # å¼ºåˆ¶é€€å‡ºï¼Œsupervisorä¼šè‡ªåŠ¨é‡å¯
            
            # å¼‚æ­¥æ‰§è¡Œé€€å‡º
            threading.Thread(target=delayed_exit, daemon=True).start()
            
            return jsonify({
                "success": True,
                "message": "æœåŠ¡æ­£åœ¨é‡å¯ï¼Œè¯·ç¨ååˆ·æ–°é¡µé¢"
            })
            
        except Exception as e:
            current_app.logger.error(f"è¿›ç¨‹é€€å‡ºæ–¹å¼å¤±è´¥: {e}")
        
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
        return jsonify({
            "success": False,
            "message": "æ— æ³•é‡å¯æœåŠ¡ï¼Œè¯·æ‰‹åŠ¨é‡å¯å®¹å™¨"
        }), 500
        
    except Exception as e:
        current_app.logger.error(f"é‡å¯å®¹å™¨å¤±è´¥: {e}", exc_info=True)
        return jsonify({"success": False, "message": f"é‡å¯å¤±è´¥: {e}"}), 500

def _get_latest_high_quality_items(count):
    """è·å–æœ€æ–°çš„é«˜ç”»è´¨é¡¹ç›®
    
    Args:
        count: è¦è·å–çš„é¡¹ç›®æ•°é‡
        
    Returns:
        list: åŒ…å«é¡¹ç›®ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
    """
    conn = get_db_connection()
    # æŸ¥è¯¢ï¼Œä»nfo_dataè¡¨ä¸­è·å–strm_name
    query = """
        SELECT m.id, m.item_path, m.bangou, m.title, p.poster_path, p.poster_status, 
               COALESCE(n.strm_name, m.bangou) as strm_name
        FROM movies m 
        LEFT JOIN pictures p ON m.id = p.movie_id 
        LEFT JOIN nfo_data n ON m.id = n.movie_id
        WHERE p.poster_status = 'é«˜ç”»è´¨' 
        ORDER BY m.created_at DESC 
        LIMIT ?
    """
    items = conn.execute(query, (count,)).fetchall()
    conn.close()
    
    # è½¬æ¢ä¸ºåˆ—è¡¨å­—å…¸
    return [dict(row) for row in items]

def init_app(app):
    app.register_blueprint(api, url_prefix='/api')
    @app.route('/api/media/<path:filename>')
    def serve_media_file(filename):
        # æ·»åŠ è°ƒè¯•æ—¥å¿—
        current_app.logger.debug(f"è¯·æ±‚è®¿é—®æ–‡ä»¶: {filename}")
        
        try:
            # ç‰¹æ®Šå¤„ç†ï¼šå°é¢ç¼“å­˜è·¯å¾„
            if filename.startswith('cover_cache/'):
                directory = 'cover_cache'
                name = filename.replace('cover_cache/', '')
                
                # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†æ”»å‡»
                if '..' in name or name.startswith('/'):
                    current_app.logger.warning(f"æ£€æµ‹åˆ°å¯èƒ½çš„è·¯å¾„éå†å°è¯•: {name}")
                    return "Forbidden", 403
                
                current_app.logger.debug(f"è®¿é—®ç¼“å­˜æ–‡ä»¶: ç›®å½•={directory}, æ–‡ä»¶å={name}")
                
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                if not os.path.exists(directory):
                    os.makedirs(directory, exist_ok=True)
                    current_app.logger.debug(f"åˆ›å»ºç¼“å­˜ç›®å½•: {directory}")
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                full_path = os.path.join(directory, name)
                if not os.path.exists(full_path):
                    current_app.logger.warning(f"ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {full_path}ï¼Œè¯·ä½¿ç”¨åˆ·æ–°ç¼“å­˜åŠŸèƒ½é‡æ–°è·å–")
                    
                    # è¿”å›404è€Œä¸æ˜¯é”™è¯¯æ¶ˆæ¯ï¼Œè¿™æ ·å‰ç«¯ä¼šæ˜¾ç¤ºå ä½å›¾åƒ
                    return "File not found", 404
                
                # æ–‡ä»¶å­˜åœ¨ï¼Œå‘é€æ–‡ä»¶
                return send_from_directory(directory, name, as_attachment=False)
            
            # ä¿®æ­£: å¤„ç†è·¯å¾„ä»¥ç¡®ä¿æ­£ç¡®çš„æƒé™æ£€æŸ¥
            full_path = f"/{filename}"
            media_root = get_media_root()
            
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            current_app.logger.debug(f"è®¿é—®åª’ä½“æ–‡ä»¶: å®Œæ•´è·¯å¾„={full_path}, åª’ä½“æ ¹è·¯å¾„={media_root}")
            
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦åœ¨å…è®¸çš„èŒƒå›´å†…
            if not is_safe_path(full_path):
                current_app.logger.warning(f"å°è¯•è®¿é—®ç¦æ­¢è·¯å¾„: {full_path}, åª’ä½“æ ¹è·¯å¾„: {media_root}")
                return "Forbidden", 403
                
            # ç¡®ä¿ç›®å½•å’Œæ–‡ä»¶åæ­£ç¡®æå–
            directory = os.path.dirname(full_path)
            name = os.path.basename(full_path)
            
            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ç›®å½•å’Œæ–‡ä»¶åä¸å«æœ‰å¯èƒ½å¯¼è‡´è·¯å¾„éå†çš„å†…å®¹
            if '..' in directory or '..' in name:
                current_app.logger.warning(f"æ£€æµ‹åˆ°å¯èƒ½çš„è·¯å¾„éå†å°è¯•: {directory}/{name}")
                return "Forbidden", 403
            
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            current_app.logger.debug(f"å‘é€æ–‡ä»¶: ç›®å½•={directory}, æ–‡ä»¶å={name}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(os.path.join(directory, name)):
                current_app.logger.warning(f"è¯·æ±‚çš„æ–‡ä»¶ä¸å­˜åœ¨: {directory}/{name}")
                return "File not found", 404
            
            return send_from_directory(directory, name, as_attachment=False)
            
        except Exception as e:
            current_app.logger.error(f"å¤„ç†åª’ä½“æ–‡ä»¶è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
            return "Internal Server Error", 500
            
    @app.route('/api/watermarks/<path:filename>')
    def serve_watermark_file(filename):
        return send_from_directory('/app/assets', filename)

    # ==================== æ€§èƒ½ä¼˜åŒ–ä¸ç›‘æ§ API ====================

    @app.route('/api/performance/database/analyze', methods=['GET'])
    def analyze_database_performance():
        """åˆ†ææ•°æ®åº“æ€§èƒ½"""
        try:
            analysis = db_performance_optimizer.analyze_database_performance()
            return jsonify({
                "success": True,
                "data": analysis
            })
        except Exception as e:
            current_app.logger.error(f"æ•°æ®åº“æ€§èƒ½åˆ†æå¤±è´¥: {e}")
            return jsonify({
                "success": False,
                "message": f"åˆ†æå¤±è´¥: {str(e)}"
            }), 500

    @app.route('/api/performance/database/optimize', methods=['POST'])
    def optimize_database():
        """ä¼˜åŒ–æ•°æ®åº“"""
        try:
            # åˆ›å»ºç¼ºå¤±çš„ç´¢å¼•
            index_result = db_performance_optimizer.create_missing_indexes()

            # æ‰§è¡ŒVACUUM
            vacuum_result = db_performance_optimizer.vacuum_database()

            return jsonify({
                "success": True,
                "data": {
                    "indexes": index_result,
                    "vacuum": vacuum_result
                }
            })
        except Exception as e:
            current_app.logger.error(f"æ•°æ®åº“ä¼˜åŒ–å¤±è´¥: {e}")
            return jsonify({
                "success": False,
                "message": f"ä¼˜åŒ–å¤±è´¥: {str(e)}"
            }), 500

    @app.route('/api/performance/cache/stats', methods=['GET'])
    def get_cache_stats():
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            stats = cache_manager.get_comprehensive_stats()
            return jsonify({
                "success": True,
                "data": stats
            })
        except Exception as e:
            current_app.logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}")
            return jsonify({
                "success": False,
                "message": f"è·å–ç»Ÿè®¡å¤±è´¥: {str(e)}"
            }), 500

    @app.route('/api/performance/cache/clear', methods=['POST'])
    def clear_cache():
        """æ¸…ç©ºç¼“å­˜"""
        try:
            cache_type = request.json.get('type', 'all') if request.json else 'all'

            if cache_type == 'all':
                result = cache_manager.clear_all_caches()
            elif cache_type == 'memory':
                cache_manager.memory_cache.clear()
                result = {'memory_cache_cleared': True}
            elif cache_type == 'file':
                result = {'file_cache_deleted': cache_manager.file_cache.clear()}
            elif cache_type == 'expired':
                result = cache_manager.cleanup_all_expired()
            else:
                return jsonify({
                    "success": False,
                    "message": "æ— æ•ˆçš„ç¼“å­˜ç±»å‹"
                }), 400

            return jsonify({
                "success": True,
                "data": result
            })
        except Exception as e:
            current_app.logger.error(f"æ¸…ç©ºç¼“å­˜å¤±è´¥: {e}")
            return jsonify({
                "success": False,
                "message": f"æ¸…ç©ºå¤±è´¥: {str(e)}"
            }), 500

    @app.route('/api/performance/monitoring/dashboard', methods=['GET'])
    def get_monitoring_dashboard():
        """è·å–ç›‘æ§é¢æ¿æ•°æ®"""
        try:
            dashboard_data = monitoring_system.get_dashboard_data()
            return jsonify({
                "success": True,
                "data": dashboard_data
            })
        except Exception as e:
            current_app.logger.error(f"è·å–ç›‘æ§æ•°æ®å¤±è´¥: {e}")
            return jsonify({
                "success": False,
                "message": f"è·å–å¤±è´¥: {str(e)}"
            }), 500

    @app.route('/api/performance/test/comprehensive', methods=['POST'])
    def run_performance_test():
        """è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•"""
        try:
            test_results = performance_tester.run_comprehensive_test()
            return jsonify({
                "success": True,
                "data": test_results
            })
        except Exception as e:
            current_app.logger.error(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            return jsonify({
                "success": False,
                "message": f"æµ‹è¯•å¤±è´¥: {str(e)}"
            }), 500

    @app.route('/api/performance/system/status', methods=['GET'])
    def get_system_status():
        """è·å–ç³»ç»ŸçŠ¶æ€æ¦‚è§ˆ"""
        try:
            # è·å–æ•°æ®åº“ç»Ÿè®¡
            from db_utils import db_manager
            db_status = db_manager.get_database_status()

            # è·å–ç¼“å­˜ç»Ÿè®¡
            cache_stats = cache_manager.get_comprehensive_stats()

            # è·å–ç›‘æ§æ•°æ®
            monitoring_data = monitoring_system.get_dashboard_data()

            return jsonify({
                "success": True,
                "data": {
                    "database": db_status,
                    "cache": cache_stats,
                    "monitoring": monitoring_data,
                    "timestamp": time.time()
                }
            })
        except Exception as e:
            current_app.logger.error(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            return jsonify({
                "success": False,
                "message": f"è·å–å¤±è´¥: {str(e)}"
            }), 500
